# TalkAI_py å®Œæ•´å®ç°ç»†èŠ‚åˆ†ææ–‡æ¡£

## 1. é¡¹ç›®æ¶æ„æ¦‚è§ˆ

### 1.1 æ ¸å¿ƒç»„ä»¶
- **main.py**: åº”ç”¨ç¨‹åºå…¥å£ç‚¹ï¼Œåˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
- **language_model.py**: æ ¸å¿ƒAIè¯­è¨€æ¨¡å‹ï¼Œå¤„ç†å¯¹è¯ã€è¯­æ³•æ£€æŸ¥ã€è¯æ±‡æ¨è
- **vocab_manager.py**: è¯æ±‡ç®¡ç†å™¨ï¼Œå¤„ç†å­¦ä¹ è¯æ±‡çš„å­˜å‚¨å’Œæ›´æ–°
- **ui.py**: PyQt5ç”¨æˆ·ç•Œé¢ï¼Œå¤„ç†æ‰€æœ‰UIäº¤äº’
- **user_profile_manager.py**: ç”¨æˆ·èµ„æ–™ç®¡ç†
- **ecdict.py**: è¯å…¸æŸ¥è¯¢åŠŸèƒ½
- **vocab_loader.py**: æŒ‰ç­‰çº§åŠ è½½è¯æ±‡
- **utils/**: å·¥å…·å‡½æ•°å’Œå¸¸é‡å®šä¹‰

### 1.2 æ•°æ®æµç¨‹
```
ç”¨æˆ·è¾“å…¥ â†’ UI â†’ LanguageModel â†’ AI API â†’ è¯­æ³•æ£€æŸ¥ â†’ è¯æ±‡æ›´æ–° â†’ UIæ˜¾ç¤º
```

## 2. æ ¸å¿ƒå®ç°ç»†èŠ‚

### 2.1 åº”ç”¨å¯åŠ¨æµç¨‹ (main.py)

```python
def main():
    # 1. åŠ è½½ç¯å¢ƒå˜é‡å’Œæ£€æŸ¥APIå¯†é’¥
    load_dotenv()
    missing_keys = check_api_keys()
    
    # 2. åˆ›å»ºå¿…è¦ç›®å½•
    setup_directories()
    
    # 3. åˆå§‹åŒ–ç”¨æˆ·èµ„æ–™ç®¡ç†å™¨
    user_profile_manager = UserProfileManager()
    user_profile = user_profile_manager.get_profile()
    
    # 4. åˆå§‹åŒ–è¯æ±‡ç®¡ç†å™¨ï¼ˆä½¿ç”¨é…ç½®çš„ä¿å­˜æ¨¡å¼ï¼‰
    vocab_manager = VocabManager(
        user_profile=user_profile,
        save_mode=config.VOCAB_SAVE_MODE,
        auto_save_interval=config.VOCAB_AUTO_SAVE_INTERVAL
    )
    
    # 5. åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
    language_model = LanguageModel(vocab_manager, user_profile, user_profile_manager)
    
    # 6. åˆ›å»ºå¹¶æ˜¾ç¤ºUI
    app = QApplication(sys.argv)
    ui = ChatUI(language_model)
    ui.show()
    
    # 7. è¿è¡Œåº”ç”¨å¹¶ç¡®ä¿èµ„æºæ¸…ç†
    try:
        sys.exit(app.exec_())
    finally:
        vocab_manager.finalize()
```

### 2.2 è¯æ±‡ç®¡ç†ç³»ç»Ÿ (vocab_manager.py)

#### 2.2.1 æ ¸å¿ƒæ•°æ®ç»“æ„
```python
# å­¦ä¹ è¯æ±‡æ¡ç›®æ ¼å¼
{
    "word": "example",
    "source": "wrong_use|right_use|lookup|user_input|level_vocab",
    "level": "CET4",
    "added_date": "2024-01-01",
    "last_used": "2024-01-15",
    "right_use_count": 3,    # æ­£ç¡®ä½¿ç”¨æ¬¡æ•°
    "wrong_use_count": 1,    # é”™è¯¯ä½¿ç”¨æ¬¡æ•°
    "isMastered": True       # right_use_count - wrong_use_count >= 3
}
```

#### 2.2.2 æ ¸å¿ƒç®—æ³•å®ç°

**è¯æ±‡æŒæ¡åº¦è®¡ç®—**ï¼š
```python
# æŒæ¡åº¦åˆ¤æ–­é€»è¾‘
if item["right_use_count"] - item["wrong_use_count"] >= 3:
    item["isMastered"] = True
else:
    item["isMastered"] = False
```

**å‘é‡æ•°æ®åº“æ„å»º**ï¼š
```python
def _build_word_vectors(self):
    # åªä¸ºæœªæŒæ¡çš„è¯æ±‡æ„å»ºå‘é‡ï¼ˆisMastered=Falseï¼‰
    unmastered_words = [item["word"] for item in self.learning_vocab 
                       if not item.get("isMastered", True)]
    
    # ä½¿ç”¨sentence transformerç”Ÿæˆè¯åµŒå…¥
    self.word_embeddings = embedding_model.encode(unmastered_words)
    self.word_to_index = {word: idx for idx, word in enumerate(unmastered_words)}
```

**å¼‚æ­¥è¯æ±‡æ›´æ–°**ï¼š
```python
def _update_vocab_background(self, word, source):
    # wrong_use_count += 1 çš„æƒ…å†µï¼š
    # - "user_input": ç”¨æˆ·è¾“å…¥ä¸­çš„é”™è¯¯
    # - "lookup": è¯å…¸æŸ¥è¯¢çš„è¯æ±‡
    # - "wrong_use": è¯­æ³•çº æ­£ä¸­çš„é”™è¯¯è¯æ±‡
    
    # right_use_count += 1 çš„æƒ…å†µï¼š
    # - "right_use": ç”¨æˆ·è¾“å…¥ä¸­çš„æ­£ç¡®è¯æ±‡
    
    if source in ["user_input", "lookup", "wrong_use"]:
        item["wrong_use_count"] += 1
    elif source == "right_use":
        item["right_use_count"] += 1
```

#### 2.2.3 æ‰¹é‡ä¿å­˜æœºåˆ¶
```python
# ä¸‰ç§ä¿å­˜æ¨¡å¼
VOCAB_SAVE_MODE = "auto_save"  # å®šæ—¶è‡ªåŠ¨ä¿å­˜
VOCAB_SAVE_MODE = "on_exit"    # é€€å‡ºæ—¶ä¿å­˜

# å¢é‡å‘é‡æ›´æ–°ï¼ˆé¿å…é‡å»ºæ•´ä¸ªå‘é‡æ•°æ®åº“ï¼‰
def _add_word_vectors(self, new_words):
    new_embeddings = embedding_model.encode(new_words)
    self.word_embeddings = np.vstack([self.word_embeddings, new_embeddings])
```

### 2.3 è¯­è¨€æ¨¡å‹æ ¸å¿ƒé€»è¾‘ (language_model.py)

#### 2.3.1 æ¶ˆæ¯å¤„ç†æµç¨‹
```python
# UIå‘é€æ¶ˆæ¯çš„å®Œæ•´æµç¨‹ï¼ˆui.pyä¸­çš„MessageProcessingThreadï¼‰
def run(self):
    # æ­¥éª¤1: ç”ŸæˆAIè‡ªç„¶å›å¤
    response = self.language_model.generate_response_natural(user_message)
    ai_message = response.get("text")
    self.ai_response_ready.emit(ai_message)
    
    # æ­¥éª¤2: å‡†å¤‡TTSéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰
    if config.TTS_ENABLED:
        self.audio_ready.emit(ai_message)
    
    # æ­¥éª¤3: æ£€æŸ¥è¯­æ³•çº é”™å’Œè¯æ±‡
    corrected_info = self.language_model.check_vocab_from_input(user_message)
    if corrected_input != user_message:
        self.correction_ready.emit(corrected_input, words_deserve_to_learn, is_valid, explanation)
    
    # æ­¥éª¤4: ç”Ÿæˆè¯æ±‡å»ºè®®
    suggested_words = self.language_model.find_vocabulary_from_last_turn(user_message, ai_message)
    if suggested_words:
        self.vocabulary_ready.emit(suggested_words)
    
    # æ­¥éª¤5: å¼‚æ­¥æ›´æ–°è¯æ±‡åº“
    if corrected_info:
        self.language_model.update_vocab_oneturn_async(corrected_info, user_message)
```

#### 2.3.2 AIå¯¹è¯ç”Ÿæˆ
```python
def generate_response_natural(self, user_input, is_voice_input=False):
    # 1. åˆ›å»ºç³»ç»Ÿæç¤ºï¼ˆåŸºäºç”¨æˆ·profileï¼‰
    system_prompt = self._create_system_prompt()
    
    # 2. æ„å»ºæ¶ˆæ¯å†å²ï¼ˆä½¿ç”¨LangChainå†…å­˜ï¼‰
    messages = [
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{human_input}")
    ]
    
    # 3. è°ƒç”¨AI APIï¼ˆæ”¯æŒMoonshot/OpenAIï¼‰
    chain = prompt | self.chat_model
    response = chain.invoke({
        "chat_history": self.memory.load_memory_variables({}).get("chat_history", []),
        "human_input": user_input
    })
    
    # 4. ä¿å­˜åˆ°å¯¹è¯å†å²
    self.memory.save_context(
        {"human_input": user_input},
        {"ai_output": response.content}
    )
    
    return {"text": response.content}
```

#### 2.3.3 è¯­æ³•æ£€æŸ¥ä¸è¯æ±‡çº é”™
```python
def check_vocab_from_input(self, user_input):
    # ä½¿ç”¨ä¸“é—¨çš„è¯­æ³•æ£€æŸ¥æç¤ºè¯
    system_prompt = system_prompt_for_check_vocab
    messages = [
        ("system", system_prompt),
        ("human", "{human_input}")
    ]
    
    # è°ƒç”¨AIè¿›è¡Œè¯­æ³•æ£€æŸ¥
    response = chain.invoke({"human_input": user_input})
    
    # è§£æJSONå“åº”
    parsed_response = json.loads(response.content)
    
    return {
        "corrected_input": parsed_response.get("corrected_input"),
        "words_deserve_to_learn": parsed_response.get("words_deserve_to_learn", []),
        "is_valid": parsed_response.get("is_valid", False),
        "explanation": parsed_response.get("explanation", "")
    }
```

#### 2.3.4 åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„è¯æ±‡æ¨è
```python
def find_vocabulary_from_last_turn(self, user_input, ai_response):
    # 1. æå–æœ€åä¸€è½®å¯¹è¯æ–‡æœ¬
    last_turn_text = " ".join([user_input, ai_response])
    
    # 2. ç”Ÿæˆå¯¹è¯å†…å®¹çš„è¯åµŒå…¥
    history_embedding = embedding_model.encode(last_turn_text)
    
    # 3. è®¡ç®—ä¸æœªæŒæ¡è¯æ±‡çš„ç›¸ä¼¼åº¦
    if (hasattr(self.vocab_manager, 'word_embeddings') and 
        len(self.vocab_manager.word_embeddings) > 0):
        
        word_embeddings = self.vocab_manager.word_embeddings
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = np.dot(word_embeddings, history_embedding) / (
            np.linalg.norm(word_embeddings, axis=1) * np.linalg.norm(history_embedding)
        )
        
        # è·å–è¯æ±‡åˆ—è¡¨
        words = list(self.vocab_manager.word_to_index.keys())
        
        # åˆ›å»º(è¯æ±‡, ç›¸ä¼¼åº¦)å¯¹å¹¶æ’åº
        word_sim_pairs = [(words[i], float(similarities[i])) for i in range(len(words))]
        word_sim_pairs.sort(key=lambda x: x[1], reverse=True)
        
        # è¿”å›TOP_Nä¸ªæœ€ç›¸ä¼¼çš„è¯æ±‡
        max_words = min(config.TOP_N_VOCAB, 10)
        return [word for word, sim in word_sim_pairs[:max_words]]
    
    return []
```

#### 2.3.5 è¯æ±‡åº“æ›´æ–°é€»è¾‘
```python
def update_vocab_oneturn_async(self, correction_result, user_input):
    # åªåœ¨is_valid=Trueæ—¶æ›´æ–°è¯æ±‡åº“
    if not correction_result.get("is_valid", False):
        return
    
    corrected_input = correction_result.get("corrected_input")
    words_deserve_to_learn = correction_result.get("words_deserve_to_learn", [])
    
    # å¤„ç†é”™è¯¯ä½¿ç”¨çš„è¯æ±‡
    if words_deserve_to_learn:
        for word_pair in words_deserve_to_learn:
            original = word_pair.get("original")
            corrected = word_pair.get("corrected")
            error_type = word_pair.get("error_type")
            
            # åªä¿å­˜æœ‰ä»·å€¼çš„è¯æ±‡ç±»å‹ï¼ˆè¿‡æ»¤è¯­æ³•å’Œæ­é…é”™è¯¯ï¼‰
            if error_type in ["translation", "vocabulary"]:
                if (not has_chinese(corrected) and 
                    len(corrected.split()) == 1 and 
                    len(corrected) > 2 and 
                    corrected not in simple_words):
                    self.vocab_manager.update_learning_vocab_async(corrected, "wrong_use")
    
    # å¤„ç†æ­£ç¡®ä½¿ç”¨çš„è¯æ±‡
    if corrected_input:
        # æ‰¾å‡ºåŸå§‹è¾“å…¥å’Œä¿®æ­£åè¾“å…¥çš„å…±åŒè¯æ±‡ï¼ˆæ­£ç¡®ä½¿ç”¨ï¼‰
        original_words = set(re.findall(r'\b\w+\b', user_input.lower()))
        corrected_words = set(re.findall(r'\b\w+\b', corrected_input.lower()))
        common_words = original_words.intersection(corrected_words)
        correct_used_words = common_words - simple_words
    else:
        # è¾“å…¥å®Œå…¨æ­£ç¡®ï¼Œæå–æ‰€æœ‰éç®€å•è¯æ±‡
        if not words_deserve_to_learn and not has_chinese(user_input):
            all_words = set(re.findall(r'\b\w+\b', user_input.lower()))
            correct_used_words = all_words - simple_words
    
    # æ›´æ–°æ­£ç¡®ä½¿ç”¨çš„è¯æ±‡
    for word in correct_used_words:
        if len(word) > 2:
            self.vocab_manager.update_learning_vocab_async(word, "right_use")
```

### 2.4 UIç•Œé¢å®ç°ç»†èŠ‚ (ui.py)

#### 2.4.1 æ¶ˆæ¯å¤„ç†çº¿ç¨‹æ¨¡å¼
```python
class MessageProcessingThread(QThread):
    # å®šä¹‰ä¿¡å·ç”¨äºä¸UIé€šä¿¡
    ai_response_ready = pyqtSignal(str)        # AIå›å¤å‡†å¤‡å°±ç»ª
    audio_ready = pyqtSignal(str)              # éŸ³é¢‘å‡†å¤‡å°±ç»ª
    correction_ready = pyqtSignal(str, list, bool, str)  # è¯­æ³•çº é”™å‡†å¤‡å°±ç»ª
    vocabulary_ready = pyqtSignal(list)        # è¯æ±‡å»ºè®®å‡†å¤‡å°±ç»ª
    profile_updated = pyqtSignal()             # ç”¨æˆ·èµ„æ–™å·²æ›´æ–°
    task_completed = pyqtSignal()              # æ‰€æœ‰ä»»åŠ¡å®Œæˆ
```

#### 2.4.2 è¯­æ³•çº é”™æ˜¾ç¤ºé€»è¾‘
```python
def add_corrected_input(self, corrected_input, words_deserve_to_learn, explanation=""):
    # 1. è®¡ç®—çº é”™ä¿¡å¿ƒæŒ‡æ ‡
    confidence_level = self.calculate_correction_confidence(words_deserve_to_learn)
    confidence_indicator = self.get_confidence_indicator(confidence_level)
    
    # 2. è®¾ç½®åŸºç¡€é¢œè‰²ï¼ˆç»¿è‰²è¡¨ç¤ºæ­£ç¡®éƒ¨åˆ†ï¼‰
    highlighted_input = f'<span style="color: #27ae60;">{corrected_input}</span>'
    
    # 3. é«˜äº®é”™è¯¯è¯æ±‡
    if words_deserve_to_learn:
        for word_pair in words_deserve_to_learn:
            corrected = word_pair.get("corrected")
            error_type = word_pair.get("error_type", "vocabulary")
            
            # ä½¿ç”¨æ™ºèƒ½åŒ¹é…æŸ¥æ‰¾è¯æ±‡å˜å½¢
            variant_word = self.find_word_variants_in_text(corrected, corrected_input)
            if variant_word:
                # æ ¹æ®é”™è¯¯ç±»å‹ä½¿ç”¨ä¸åŒé¢œè‰²
                color = self.get_error_type_color(error_type)
                pattern = r'\b' + re.escape(variant_word) + r'\b'
                replacement = f'<b style="color: {color};">{variant_word}</b>'
                highlighted_input = re.sub(pattern, replacement, highlighted_input, flags=re.IGNORECASE)
    
    # 4. æ˜¾ç¤ºçº é”™ç»“æœ
    self.chat_display.append(f'<p><i>{confidence_indicator} Corrected: {highlighted_input}</i></p>')
    
    # 5. æ˜¾ç¤ºè§£é‡Šè¯´æ˜
    if explanation.strip():
        self.chat_display.append(f'<p><i>ğŸ’¡ {explanation}</i></p>')
```

#### 2.4.3 æ™ºèƒ½è¯æ±‡å˜å½¢åŒ¹é…
```python
def find_word_variants_in_text(self, target_word, text):
    # æ”¯æŒçš„å˜å½¢æƒ…å†µï¼š
    # - å¤æ•°å½¢å¼: catâ†’cats, childâ†’children
    # - åŠ¨è¯æ—¶æ€: runâ†’running, goâ†’went, writeâ†’written
    # - æ¯”è¾ƒçº§/æœ€é«˜çº§: bigâ†’biggerâ†’biggest
    # - å¸¸è§åç¼€: -s, -es, -ed, -ing, -er, -est, -ly
    
    common_suffixes = ['s', 'es', 'ed', 'ing', 'er', 'est', 'ly', 'tion', 'sion', 'ness', 'ment']
    
    # 1. ç²¾ç¡®åŒ¹é…
    exact_pattern = r'\b' + re.escape(target_word) + r'\b'
    if re.search(exact_pattern, text, flags=re.IGNORECASE):
        return target_word
    
    # 2. è¯æ ¹åŒ¹é…
    words_in_text = re.findall(r'\b\w+\b', text.lower())
    target_lower = target_word.lower()
    
    for word in words_in_text:
        # æ£€æŸ¥æ˜¯å¦ä»¥ç›®æ ‡è¯å¼€å¤´
        if word.startswith(target_lower) and len(word) > len(target_lower):
            suffix = word[len(target_lower):]
            if suffix.isalpha() and (suffix in common_suffixes or len(suffix) <= 3):
                return word
    
    return None
```

#### 2.4.4 é”™è¯¯ç±»å‹é¢œè‰²æ˜ å°„
```python
def get_error_type_color(self, error_type):
    color_map = {
        "translation": "#e74c3c",    # çº¢è‰² - ç¿»è¯‘é”™è¯¯
        "vocabulary": "#f39c12",     # æ©™è‰² - è¯æ±‡é”™è¯¯
        "collocation": "#9b59b6",    # ç´«è‰² - æ­é…é”™è¯¯
        "grammar": "#2980b9"         # è“è‰² - è¯­æ³•é”™è¯¯
    }
    return color_map.get(error_type, "#e74c3c")
```

#### 2.4.5 è¯æ±‡å»ºè®®æ˜¾ç¤º
```python
def on_vocabulary_ready(self, suggested_words):
    word_list = ", ".join([f"<b>{word}</b>" for word in suggested_words])
    self.add_system_message(f"Suggested vocabulary: {word_list}")
    self.chat_display.moveCursor(QTextCursor.End)
```

### 2.5 è¯å…¸åŠŸèƒ½å®ç° (ecdict.py)

#### 2.5.1 è¯å…¸æŸ¥è¯¢æµç¨‹
```python
def lookup_word(self, word):
    dictionary = self._get_dictionary()  # è¿æ¥å¤ç”¨
    
    # è‡ªåŠ¨æ£€æµ‹æŸ¥è¯¢æ–¹å‘
    reverse = is_chinese(word)
    
    if reverse:
        # ä¸­æ–‡æŸ¥è‹±æ–‡
        results = search_chinese_in_translation(self._dict_path, word, limit=10)
        return format_multiple_word_results(results, limit=10)
    else:
        # è‹±æ–‡æŸ¥ä¸­æ–‡
        word_data = dictionary.query(word)
        return format_word_result(word_data)
```

#### 2.5.2 è¯å…¸æŸ¥è¯¢åçš„è¯æ±‡æ·»åŠ 
```python
def handle_word_lookup(self):
    word = self.word_input.toPlainText().strip()
    definition = self.language_model.lookup_word(word)
    
    # æ˜¾ç¤ºè¯å…¸ç»“æœ
    self.vocab_display.setHtml(formatted_definition)
    
    # å¦‚æœæ˜¯è‹±æ–‡è¯æ±‡ï¼Œæ·»åŠ åˆ°å­¦ä¹ è¯æ±‡è¡¨
    if not has_chinese(word):
        success = self.language_model.vocab_manager.update_learning_vocab_async(word, "lookup")
        if success:
            self.add_system_message(f"âœ“ Added vocabulary: '{word}' to learning list.")
```

### 2.6 ç”¨æˆ·ç­‰çº§è¯æ±‡åŠ è½½ (vocab_loader.py)

#### 2.6.1 ç­‰çº§è¯æ±‡æ˜ å°„
```python
grade_to_txt_file = {
    "Primary School": "primary_school_all.txt",
    "Middle School": "middle_school_all.txt", 
    "High School": "high_school_all.txt",
    "CET4": "CET4_all.txt",
    "CET6": "CET6_all.txt",
    "TOEFL": "TOEFL_all.txt",
    "IELTS": "IELTS_all.txt",
    "GRE": "GRE_all.txt"
}
```

#### 2.6.2 è¯æ±‡åŠ è½½é€»è¾‘
```python
def load_vocab_by_grade(self, user_id="default_user"):
    # 1. æ£€æŸ¥æ˜¯å¦å·²æ·»åŠ è¿‡æ­¤ç­‰çº§
    added_vocab_levels = profile.get("added_vocab_levels", [])
    if grade in added_vocab_levels:
        return False
    
    # 2. ä»txtæ–‡ä»¶è¯»å–è¯æ±‡
    words_from_txt = self._read_txt_words(txt_file_path)
    
    # 3. å¤„ç†è¯æ±‡ï¼šæ›´æ–°å·²å­˜åœ¨çš„ï¼Œæ·»åŠ æ–°çš„
    for word in words_from_txt:
        if word in existing_words:
            # æ›´æ–°sourceå’Œlevel
            self._update_existing_word(vocab_dict[word], grade)
        else:
            # åˆ›å»ºæ–°è¯æ±‡æ¡ç›®
            new_entry = self._create_word_entry(word, grade)
            current_vocab.append(new_entry)
    
    # 4. ä¿å­˜å¹¶è®°å½•å·²æ·»åŠ ç­‰çº§
    current_added_levels.append(grade)
    self.profile_manager.update_profile(user_id, {"added_vocab_levels": current_added_levels})
```

### 2.7 è‡ªåŠ¨æ¶ˆæ¯ç”Ÿæˆ

#### 2.7.1 å®šæ—¶æ£€æŸ¥é€»è¾‘
```python
def send_auto_message(self):
    current_time = QDateTime.currentDateTime()
    elapsed_minutes = self.last_message_time.secsTo(current_time) / 60
    
    # æ£€æŸ¥æ¡ä»¶ï¼šæœ€åæ¶ˆæ¯æ˜¯AIçš„ï¼Œè¶…è¿‡æ—¶é—´é—´éš”ï¼Œæœªå‘é€è¿‡è‡ªåŠ¨æ¶ˆæ¯
    if (self.last_message_is_ai and 
        elapsed_minutes >= config.AUTO_MESSAGE_INTERVAL and 
        not self.auto_message_sent):
        
        # ç”Ÿæˆæ–°è¯é¢˜
        response = self.language_model.generate_new_conversation()
        self.add_ai_message(response["text"])
        self.auto_message_sent = True
```

## 3. å…³é”®é…ç½®å‚æ•°

### 3.1 è¯æ±‡ç®¡ç†é…ç½®
```python
# è¯æ±‡è®¾ç½®
TOP_N_VOCAB = 5                    # æ¨èè¯æ±‡æ•°é‡
VOCAB_SAVE_MODE = "auto_save"      # ä¿å­˜æ¨¡å¼ï¼šauto_save/on_exit  
VOCAB_AUTO_SAVE_INTERVAL = 3       # è‡ªåŠ¨ä¿å­˜é—´éš”ï¼ˆç§’ï¼‰

# è®°å¿†è®¾ç½®
MAX_MEMORY_TURNS = 3               # å¯¹è¯å†å²è½®æ•°

# æŒæ¡åº¦é˜ˆå€¼
MASTERY_THRESHOLD = 3              # right_use - wrong_use >= 3

# UIè®¾ç½®
AUTO_MESSAGE_INTERVAL = 0.5        # è‡ªåŠ¨æ¶ˆæ¯é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
```

### 3.2 AIæ¨¡å‹è®¾ç½®
```python
# æ¨¡å‹é…ç½®
MODEL_PROVIDER = "moonshot"        # moonshot/openai
MOONSHOT_MODEL = "moonshot-v1-8k"
OPENAI_MODEL = "gpt-3.5-turbo"

# åµŒå…¥æ¨¡å‹
EMBEDDING_MODEL = "all-MiniLM-L6-v2"
```

## 4. æ•°æ®å­˜å‚¨ç»“æ„

### 4.1 å­¦ä¹ è¯æ±‡æ–‡ä»¶ (learning_vocab.json)
```json
[
  {
    "word": "example",
    "source": "wrong_use",
    "level": "CET4", 
    "added_date": "2024-01-01",
    "last_used": "2024-01-15",
    "right_use_count": 5,
    "wrong_use_count": 2,
    "isMastered": true
  }
]
```

### 4.2 ç”¨æˆ·èµ„æ–™æ–‡ä»¶ (user_profiles.json)
```json
{
  "default_user": {
    "age": 16,
    "gender": "Male",
    "grade": "High School",
    "added_vocab_levels": ["Primary School", "Middle School", "High School"]
  }
}
```

## 5. ç³»ç»Ÿæç¤ºè¯è®¾è®¡

### 5.1 è¯­æ³•æ£€æŸ¥æç¤ºè¯ (utils/const.py)
```python
system_prompt_for_check_vocab = """
ä½ æ˜¯ä¸€ä¸ªè‹±è¯­å­¦ä¹ åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·çº æ­£è‹±è¯­é”™è¯¯å¹¶è¯†åˆ«éœ€è¦å­¦ä¹ çš„è¯æ±‡ã€‚

è¯·åˆ†æç”¨æˆ·è¾“å…¥çš„è‹±è¯­å¥å­ï¼Œæ£€æŸ¥ä»¥ä¸‹æ–¹é¢ï¼š
1. è¯­æ³•é”™è¯¯
2. è¯æ±‡ä½¿ç”¨é”™è¯¯
3. æ­é…é”™è¯¯
4. ç¿»è¯‘é”™è¯¯

è¿”å›JSONæ ¼å¼ï¼š
{
  "corrected_input": "çº æ­£åçš„å¥å­",
  "words_deserve_to_learn": [
    {
      "original": "åŸå§‹é”™è¯¯è¯æ±‡",
      "corrected": "æ­£ç¡®è¯æ±‡", 
      "error_type": "translation|vocabulary|grammar|collocation",
      "explanation": "é”™è¯¯è§£é‡Š"
    }
  ],
  "is_valid": true/false,
  "explanation": "æ•´ä½“è§£é‡Š"
}
"""
```

### 5.2 å¯¹è¯ç³»ç»Ÿæç¤ºè¯
```python
BASE_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªè‹±è¯­å­¦ä¹ åŠ©æ‰‹ï¼Œé€šè¿‡è‡ªç„¶å¯¹è¯å¸®åŠ©ç”¨æˆ·ç»ƒä¹ è‹±è¯­ã€‚
- ä½¿ç”¨é€‚åˆç”¨æˆ·æ°´å¹³çš„è¯æ±‡å’Œè¯­æ³•
- å›å¤ç®€æ´è‡ªç„¶ï¼Œ1-2å¥è¯
- é¼“åŠ±ç”¨æˆ·ç»§ç»­å¯¹è¯
- ä¸è¦ä¸»åŠ¨çº æ­£é”™è¯¯ï¼ˆæœ‰ä¸“é—¨çš„çº é”™æ¨¡å—ï¼‰
"""
```

## 6. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 6.1 å¼‚æ­¥å¤„ç†
- è¯æ±‡æ›´æ–°ä½¿ç”¨çº¿ç¨‹æ± å¼‚æ­¥å¤„ç†
- UIä¸é˜»å¡ï¼Œå®æ—¶å“åº”ç”¨æˆ·æ“ä½œ
- æ‰¹é‡ä¿å­˜æœºåˆ¶å‡å°‘I/Oæ“ä½œ

### 6.2 å‘é‡æ•°æ®åº“ä¼˜åŒ–
- åªä¸ºæœªæŒæ¡è¯æ±‡æ„å»ºå‘é‡
- å¢é‡æ›´æ–°é¿å…é‡å»ºæ•´ä¸ªå‘é‡åº“
- ä½¿ç”¨numpyä¼˜åŒ–ç›¸ä¼¼åº¦è®¡ç®—

### 6.3 å†…å­˜ç®¡ç†
- è¯å…¸è¿æ¥å¤ç”¨
- å¯¹è¯å†å²é™åˆ¶è½®æ•°
- å®šæ—¶å™¨ç®¡ç†å’Œèµ„æºæ¸…ç†

## 7. æ€»ç»“

TalkAI_pyçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š

1. **æ™ºèƒ½è¯­æ³•çº é”™**ï¼šåŸºäºAIçš„è¯­æ³•æ£€æŸ¥å’Œè¯æ±‡è¯†åˆ«
2. **è¯­ä¹‰è¯æ±‡æ¨è**ï¼šä½¿ç”¨å¥å­åµŒå…¥è¿›è¡Œä¸Šä¸‹æ–‡ç›¸å…³çš„è¯æ±‡æ¨è  
3. **æŒæ¡åº¦è¿½è¸ª**ï¼šåŸºäºä½¿ç”¨é¢‘ç‡çš„æ™ºèƒ½æŒæ¡åº¦åˆ¤æ–­
4. **å¼‚æ­¥æ¶æ„**ï¼šéé˜»å¡çš„ç”¨æˆ·ä½“éªŒ
5. **å¤šæ¨¡æ€UI**ï¼šä¿¡å¿ƒæŒ‡æ ‡ã€é¢œè‰²ç¼–ç ã€æ™ºèƒ½åŒ¹é…ç­‰é«˜çº§UIåŠŸèƒ½

è¿™ä¸ªç³»ç»Ÿå°†è‹±è¯­å­¦ä¹ ä¸AIæŠ€æœ¯æ·±åº¦ç»“åˆï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸ªæ€§åŒ–ã€æ™ºèƒ½åŒ–çš„è‹±è¯­å­¦ä¹ ä½“éªŒã€‚